# Deep learning
# project objectives
1. Understanding the knowledge of neural networks and diverse models  
2. Being  able  to  program  to  achieve  models  for  a  tailored context 
3. Being able to apply neural network models (including deep learning models) to a required application

# Assigment Documentation
[CE889-SP Assignment Brief 2022.pdf](https://github.com/micsupasun/university_of_essex/blob/main/neural_networks_and_deep_learning/CE889-SP%20Assignment%20Brief%202022.pdf) is the homework file I got from a professor teaching Deep learning.

# Lab File
This is all the lab files that create Logistic Model and neural network, and basic deep learning model

[lab1.ipynb](https://github.com/micsupasun/university_of_essex/blob/main/neural_networks_and_deep_learning/lab1.ipynb) is the first lab file practice essential python files

[lab2.ipynb](https://github.com/micsupasun/university_of_essex/blob/main/neural_networks_and_deep_learning/lab2.ipynb) is the second lab file to create scaling and rotation

[lab3.ipynb](https://github.com/micsupasun/university_of_essex/blob/main/neural_networks_and_deep_learning/lab3.ipynb) is the third lab file to create Forward propagation and loss with Sigmoid and Rectified Linear Unit activate function

[lab4.ipynb](https://github.com/micsupasun/university_of_essex/blob/main/neural_networks_and_deep_learning/lab4.ipynb) is the fourth lab file to create a function for calculating the output(forward propagation) and loss, calculating gradients(backward propagation), updating weights

[lab5.ipynb](https://github.com/micsupasun/university_of_essex/blob/main/neural_networks_and_deep_learning/lab5.ipynb) is the fifth lab file to create Logistic Model with Forward propagation and loss, gradients(backward propagation), updating weights

# Assignment File
[assignmentv2.ipynb](https://github.com/micsupasun/university_of_essex/blob/main/neural_networks_and_deep_learning/assignmentv2.ipynb) is the assignment file to work including:

1. clean data
2. create activation(sigmoid, tanh, relu, leaky relu), 
3. create a function Forward propagation, 
4. create loss function, 
5. create backward propagation.
6. train model with k-fold cross validation
7. fine-tuning parameter to improve accuracy with grid search and the random search
8. predict and show accuracy by classification report and confusion matrix and accuracy